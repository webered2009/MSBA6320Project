confusionMatrix(testing$diagnosis,predict(modelFit,testPC))
names(testing)
preProc
preProc <- preProcess(training[,-1],method="pca", thresh=0.8)
testPC <- predict(preProc,testing[,-1])
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca", data = training)
testPC
preProc <- preProcess(training[,-1],method="pca", thresh=0.8)
testPC <- predict(preProc,testing[,-1])
testPC
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training <- training[,c("diagnosis",colnames(adData)[grep("IL", colnames(adData))])]
testing <- testing[,c("diagnosis",colnames(adData)[grep("IL", colnames(adData))])]
preProc <- preProcess(training[,-1],method="pca", thresh=0.8)
testPC <- predict(preProc,testing[,-1])
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca", data = training)
testPC
preProc
modelFit
testing
confusionMatrix(testing$diagnosis,predict(modelFit,testPC))
testing
names(testing)
names(training)
training <- training[,c("diagnosis",colnames(adData)[grep("^IL", colnames(adData))])]
names(training)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training <- training[,c("diagnosis",colnames(adData)[grep("^IL", colnames(adData))])]
testing <- testing[,c("diagnosis",colnames(adData)[grep("^IL", colnames(adData))])]
preProc <- preProcess(training[,-1],method="pca", thresh=0.8)
testPC <- predict(preProc,testing[,-1])
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca", data = training)
confusionMatrix(testing$diagnosis,predict(modelFit,testPC))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training <- training[,c("diagnosis",colnames(adData)[grep("^IL", colnames(adData))])]
testing <- testing[,c("diagnosis",colnames(adData)[grep("^IL", colnames(adData))])]
preProc <- preProcess(log10(training[,-1]+1),method="pca", thresh=0.8)
testPC <- predict(preProc,log10(testing[,-1]+1))
trainPC <- predict(preProc, log10(training[,-1]+1))
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca", data = trainPC)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
preProc <- preProcess(log10(training[,-1]+1),method="pca", thresh=0.8)
colnames(training)
colnames(preProc)
training <- training[,c("diagnosis",colnames(adData)[grep("^IL", colnames(adData))])]
testing <- testing[,c("diagnosis",colnames(adData)[grep("^IL", colnames(adData))])]
colnames(preProc)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training <- training[,c("diagnosis",colnames(adData)[grep("^IL", colnames(adData))])]
testing <- testing[,c("diagnosis",colnames(adData)[grep("^IL", colnames(adData))])]
names(training)
names(testing)
summary(training)
preProc <- preProcess(log10(training[,-1]+10),method="pca", thresh=0.8)
testPC <- predict(preProc,log10(testing[,-1]+10))
trainPC <- predict(preProc, log10(training[,-1]+10))
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca", data = trainPC)
confusionMatrix(testing$diagnosis,predict(modelFit,testPC))
ModelFit2 <- train(diagnosis ~ ., method="glm", preProcess="pca", data=training)
confusionMatrix(testing$diagnosis, predict(ModelFit2, testing))
confusionMatrix(testing$diagnosis,predict(modelFit,testPC))
confusionMatrix(testing$diagnosis, predict(ModelFit2, testing))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training <- training[,c("diagnosis",colnames(adData)[grep("^IL", colnames(adData))])]
testing <- testing[,c("diagnosis",colnames(adData)[grep("^IL", colnames(adData))])]
preProc <- preProcess(log10(training[,-1]+10),method="pca", thresh=0.8)
testPC <- predict(preProc,log10(testing[,-1]+10))
trainPC <- predict(preProc, log10(training[,-1]+10))
modelFit <- train(training$diagnosis ~ ., method = "glm", preProcess = "pca", data = trainPC)
confusionMatrix(testing$diagnosis,predict(modelFit,testPC))
ModelFit2 <- train(diagnosis ~ ., method="glm", preProcess="pca", data=training)
confusionMatrix(testing$diagnosis, predict(ModelFit2, testing))
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y = iris$Species,
p = 0.7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
dim(testing)
qplot(Petal.Width, Sepal.Width, colour = Species, data = training)
library(caret)
modFit <- train(Species ~ ., method = "rpart", data = training)
print(modFit$finalModel)
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = 0.8)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = 0.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = 0.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(caret)
modFit <- train(Species ~ ., method = "rpart", data = training)
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = 0.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
predict(modFit, newdata = testing)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(ozone, package= "ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
ll <- matrix(NA, nrow=10, ncol=155)
for(i in 1:10) {
# resample 10 times, sample with replacement, create ozone0 new resample, reorder by ozone,
# fit loess (smooth curve, like spline) of temp and ozone, using resampled dataset each time
# predict for each, an outcome for each
ss <- sample(1:dim(ozone)[1], replace=T)
ozone0 <- ozone[ss,]
ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone, data=ozone0, span=0.2)
ll[i,] <- predict(loess0, newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone, ozone$temperature, pch=19, cex=0.5)
for(i in 1:10) {lines(1:155, ll[i,], col='grey', lwd=2)} # 10 grey curvy lines - overcapturing variability
lines(1:155, apply(ll, 2, mean), col='red', lwd=2) # 1 red curvy line = bagged loess curve
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y = iris$Species,
p = 0.7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
library(caret)
modFit <- train(Species ~ ., data=training, method = "rf", prox = TRUE)
modFit
irisP <- classCenter(training[, c(3,4)], training$Species, modFit$finalModel$prox) # from prox=TRUE
irisP <- as.data.frame(irisP)
irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col=Species, data=training)
p + geom_point(aes(x=Petal.Width, y=Petal.Length, col=Species), size=5, shape=4, data=irisP)
pred <- predict(modFit, testing)
tesing$predRight <- pred == testing$Species
table(pred, testing$Species) # 2 missed
qplot(Petal.Width, Petal.Length, color=predRight, data=testing, main='newdata Predictions')
pred <- predict(modFit, testing)
testing$predRight <- pred == testing$Species
table(pred, testing$Species) # 2 missed
qplot(Petal.Width, Petal.Length, color=predRight, data=testing, main='newdata Predictions')
table(pred, testing$Species)
library(ISLR); library(ggplot2); library(caret);
data(Wage)
summary(Wage) # year, age, sex, maritl, race, education, region, jobclass, health
Wage <- subset(Wage, select=-c(logwage)) # remove the logwage variable, the one we are trying to predict
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=F)
training <- Wage[inTrain, ]
testing <- Wage[-inTrain, ]
modFit <- train(wage ~ ., method='gbm', data=training, verbose=FALSE) # would be lots of output
print(modFit)
qplot(predict(modFit, testing), wage, data=testing) # has group up above, as was seen in earlier data
modlda = train(Species ~ ., data=training, method='lda')
modnb = train(Species ~ ., data=training, method='nb')
plda = predict(modlda, testing)
pnb = predict(modnb, testing)
table(plda, pnb)
data(iris)
library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y = iris$Species,
p = 0.7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modlda = train(Species ~ ., data=training, method='lda')
modnb = train(Species ~ ., data=training, method='nb')
plda = predict(modlda, testing)
pnb = predict(modnb, testing)
table(plda, pnb)
equalPredictions = (plda==pnb)
qplot(Petal.Width, Sepal.Width, color=equalPredictions, data=testing)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
names(segmentationOriginal)
inTrain <- createDataPartition(y = segmentationOriginal$Case,
p = 0.7, list = FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
dim(testing)
set.seed(125)
modfit1 <- train(Case ~ ., method = "rpart", data=training)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training)
dim(testing)
set.seed(125)
modfit1 <- train(Case ~ ., method = "rpart", data=training)
inTrain <- createDataPartition(y = segmentationOriginal$Case,
p = 0.7, list = FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
dim(testing)
set.seed(125)
modfit1 <- train(Case ~ ., method = "rpart", data=training)
modfit1
plot(modfit1$finalModel, uniform = TRUE, main = "Classification Tree")
text(modfit1$finalModel, use.n = TRUE, all = TRUE, cex = 0.8)
library(rattle)
fancyRpartPlot(modfit1$finalModel)
install.packages("rpart")
install.packages("rpart")
install.packages("rpart")
library(rattle)
fancyRpartPlot(modfit1$finalModel)
install.packages("rpart.plot")
library(rattle)
fancyRpartPlot(modfit1$finalModel)
modfit1$finalModel
## 1
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case,
p = 0.6, list = FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
dim(testing)
set.seed(125)
modfit1 <- train(Case ~ ., method = "rpart", data=training)
plot(modfit1$finalModel, uniform = TRUE, main = "Classification Tree")
text(modfit1$finalModel, use.n = TRUE, all = TRUE, cex = 0.8)
modfit1$finalModel
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case,
p = 0.6, list = FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
dim(testing)
set.seed(125)
modfit1 <- train(Class ~ ., method = "rpart", data=training)
library(rattle)
fancyRpartPlot(modfit1$finalModel)
modfit1$finalModel
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
modolive <- train(Area ~ ., method = "rpart", data = olive)
predict(modolive, newdata = newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
names(SAheart)
missClass(testSA$chd, predict(modelSA, newdata = testSA))
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
names(vowel.train)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
## 1
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case,
p = 0.6, list = FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
dim(testing)
set.seed(125)
modfit1 <- train(Class ~ ., method = "rpart", data=training)
plot(modfit1$finalModel, uniform = TRUE, main = "Classification Tree")
text(modfit1$finalModel, use.n = TRUE, all = TRUE, cex = 0.8)
library(rattle)
fancyRpartPlot(modfit1$finalModel)
modfit1$finalModel
## 1
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case,
p = 0.7, list = FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
dim(testing)
set.seed(125)
modfit1 <- train(Class ~ ., method = "rpart", data=training)
plot(modfit1$finalModel, uniform = TRUE, main = "Classification Tree")
text(modfit1$finalModel, use.n = TRUE, all = TRUE, cex = 0.8)
library(rattle)
fancyRpartPlot(modfit1$finalModel)
modfit1$finalModel
set.seed(33833)
modfit2 <- train(y ~ ., method = "rpart", data=vowel.train)
varlmp(modfit2)
library(caret)
varlmp(modfit2)
set.seed(33833)
modfit2 <- randomForest(y ~ ., data=vowel.train)
varlmp(modfit2)
library(randomForest)
library(caret)
varImp(modfit2)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
set.seed(33833)
modfit2 <- randomForest(y ~ ., data=vowel.train)
library(randomForest)
library(caret)
varImp(modfit2)
order(varImp(modfit2))
install.packages("REDCapR")
```{r, cache = TRUE}
```{r, cache = TRUE, include = FALSE}
publish(title = 'Test', 'Final_Data_Products_Project.html', host = 'rpubs')
??github
head(cars)
cars
library(datasets)
head(cars)
library(datasets)
library(datasets)
head(cars)
names(cars)
summary(cars)
dim(cars)
plot(cars)
cor(cars$speed, cars$dist)
attach(cars)
lm(dist ~ speed)
linear_model_1 <- lm(dist ~ speed)
library(datasets)
head(cars)
names(cars)
summary(cars)
dim(cars)
plot(cars)
cor(cars$speed, cars$dist)
linear_model_1 <- lm(dist ~ speed)
detach(cars)
library(datasets)
head(cars)
names(cars)
summary(cars)
dim(cars)
plot(cars)
cor(cars$speed, cars$dist)
linear_model_1 <- lm(dist ~ speed)
linear_model_1 <- lm(dist ~ speed)
linear_model_1 <- lm(dist ~ speed, data = cars)
linear_model_1
names(linear_model_1)
linear_model_1$coefficients
linear_model_1$residuals
linear_model_1$res
plot(cars$speed,cars$dist)
plot(cars$speed,cars$dist)
abline(linear_model_1)
linear_diag <- ls.diag(linear_model_1)
names(linear_diag)
linear_diag$stud.res
max(linear_diag$stud.res)
min(linear_diag$stud.res)
abs(gmst.diag$stud.res) > 2
abs(linear_diag$stud.res) > 2
cars$speed[abs(linear_diag$stud.res) > 2]
cars[abs(linear_diag$stud.res) > 2]
cars$speed[abs(linear_diag$stud.res) > 2]
cars$dist[abs(linear_diag$stud.res) > 2]
linear_diag$cooks
linear_diag <- ls.diag(linear_model_1)
names(linear_diag)
qqnorm(linear_diag$res)
linear_model_1 <- lm(dist ~ speed, data = cars)
linear_model_1$residuals
qqnorm(linear_model_1$residuals)
qqline(linear_model_1$residuals)
names(cars)
plot(speed,linear_diag$stud.res)
plot(speed,linear_diag$stud.res, data = cars)
plot(cars$speed,linear_diag$stud.res)
install.packages("twitteR")
getTwitterOAuth("IlBNmjHricqZxA0V6BbIPotWz","Tdk9LQVa7QL4eSx3r5f8Q5RFYG8qafJ1hvFxYCclGnQjt06qOK")
library(twitteR)
getTwitterOAuth("IlBNmjHricqZxA0V6BbIPotWz","Tdk9LQVa7QL4eSx3r5f8Q5RFYG8qafJ1hvFxYCclGnQjt06qOK")
?setup_twitter_oauth
setup_twitter_oauth("IlBNmjHricqZxA0V6BbIPotWz","Tdk9LQVa7QL4eSx3r5f8Q5RFYG8qafJ1hvFxYCclGnQjt06qOK")
setup_twitter_oauth("IlBNmjHricqZxA0V6BbIPotWz","Tdk9LQVa7QL4eSx3r5f8Q5RFYG8qafJ1hvFxYCclGnQjt06qOK")
library(twitteR)
setup_twitter_oauth("IlBNmjHricqZxA0V6BbIPotWz","Tdk9LQVa7QL4eSx3r5f8Q5RFYG8qafJ1hvFxYCclGnQjt06qOK")
setup_twitter_oauth("XRBNwgdUWa6n9YFkbs9t5Y7Sl","qN9FgitPDIF65QPxMhCCcOCCCnowQWnJMgVwer2Kp5gBTS3Nw1")
source('~/Dropbox/MSBA/Course_2016_Spring_HINF_5531/Week_14/AnalyzingTwitterDataHW8.R')
library(twitteR)
setup_twitter_oauth(consumer_key = "XRBNwgdUWa6n9YFkbs9t5Y7Sl",
consumer_secret = "qN9FgitPDIF65QPxMhCCcOCCCnowQWnJMgVwer2Kp5gBTS3Nw1",
access_token = "258085668-7hsqvmiHCz35szuscY3UmIKTk1FDXrCmR1rOv3Uf",
access_secret = "Sm1GdLPggORuXln6ZcaU7NpR8o09Ny8PnVb8hMxmWoGOA")
## Step 1
library(twitteR)
setup_twitter_oauth(consumer_key = "XRBNwgdUWa6n9YFkbs9t5Y7Sl",
consumer_secret = "qN9FgitPDIF65QPxMhCCcOCCCnowQWnJMgVwer2Kp5gBTS3Nw1",
access_token = "258085668-7hsqvmiHCz35szuscY3UmIKTk1FDXrCmR1rOv3Uf",
access_secret = "Sm1GdLPggORuXln6ZcaU7NpR8o09Ny8PnVb8hMxmWoGOA")
source('~/Dropbox/MSBA/Course_2016_Spring_HINF_5531/Week_14/AnalyzingTwitterDataHW8.R')
dim(missions_df)
between_tweets <- as.vector(sort(missions_df$created))
between_tweets_amount <- diff(between_tweets)
summary(between_tweets_amount)
?poisson.test?
f
?poisson.test
View(appendectomy_times)
asthma_times <- diff(sort(asthma_df$created))
diabetes_times <- diff(sort(diabetes_df$created))
appendectomy_times <- diff(sort(appendectomy_df$created))
mammogram_times <- diff(sort(mammogram_df$created))
View(mammogram_times)
asthma_times <- diff(as.vector(sort(asthma_df$created)))
diabetes_times <- diff(as.vector(sort(diabetes_df$created)))
appendectomy_times <- diff(as.vector(sort(appendectomy_df$created)))
mammogram_times <- diff(as.vector(sort(mammogram_df$created)))
max(appendectomy_times)
min(appendectomy_times)
poisson.test(c(length(asthma_times), length(diabetes_times)),
c((max(asthma_times) - min(asthma_times)), c(max(diabetes_times)) - c(min(diabetes_times))))
poisson.test(c(length(appendectomy_times), length(mammogram_times)),
c((max(appendectomy_times) - min(appendectomy_times)), c(max(mammogram_times)) - c(min(mammogram_times))))
poisson.test(c(length(asthma_times), length(diabetes_times)),
c((max(asthma_times) - min(asthma_times)), c(max(diabetes_times)) - c(min(diabetes_times))),
alternative = 'less')
poisson.test(c(length(appendectomy_times), length(mammogram_times)),
c((max(appendectomy_times) - min(appendectomy_times)), c(max(mammogram_times)) - c(min(mammogram_times))),
alternative = 'less')
PubH_6414_IP_Spring2016_MidtermFeedback <- read.csv("~/Dropbox/Job/2015-16_AnnualReview_Weber_Eric/Spring2016Feedback/PubH_6414_IP_Spring2016_MidtermFeedback.csv")
View(PubH_6414_IP_Spring2016_MidtermFeedback)
Feedback6414 <-read.csv("~/Dropbox/Job/2015-16_AnnualReview_Weber_Eric/Spring2016Feedback/PubH_6414_IP_Spring2016_MidtermFeedback.csv")
Feedback6450 <-read.csv("~/Dropbox/Job/2015-16_AnnualReview_Weber_Eric/Spring2016Feedback/PubH_6450_IP_Spring2016_MidtermFeedback.csv")
Feedback6450 <-read.csv("~/Dropbox/Job/2015-16_AnnualReview_Weber_Eric/Spring2016Feedback/PubH_6450_IP_Spring2016_MidtermFeedback.csv")
??bigdata
??autoplot
??foreign
??datacam
??datacamp
library(RSQLServer)
library(RODBC)
conn < - odbcDriverConnect("Driver=SQL Server; Server=msba6320.oit.umn.edu; Database=db_edweber; Uid=edweber; Pwd=M$3212261;")
odbcDriverConnect("Driver=SQL Server; Server=msba6320.oit.umn.edu; Database=db_edweber; Uid=edweber; Pwd=M$3212261;")
path <- "/Users/ericweber/Google\ Drive/MSBA_6320_Group_Project/Final_Report_Materials/HealthFactTableData"
setwd(path)
![alt text]("hft_1.png" "Logo Title Text 1")
